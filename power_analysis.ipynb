{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc20f0a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'readr'</li><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'performance'</li><li>'readr'</li><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'dplyr'</li><li>'performance'</li><li>'readr'</li><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'pwr'</li><li>'dplyr'</li><li>'performance'</li><li>'readr'</li><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'parallel'</li><li>'pwr'</li><li>'dplyr'</li><li>'performance'</li><li>'readr'</li><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "\t<li><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'stringr'</li><li>'parallel'</li><li>'pwr'</li><li>'dplyr'</li><li>'performance'</li><li>'readr'</li><li>'lme4'</li><li>'Matrix'</li><li>'stats'</li><li>'graphics'</li><li>'grDevices'</li><li>'utils'</li><li>'datasets'</li><li>'methods'</li><li>'base'</li></ol>\n",
       "</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'readr'\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'performance'\n",
       "\\item 'readr'\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'dplyr'\n",
       "\\item 'performance'\n",
       "\\item 'readr'\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'pwr'\n",
       "\\item 'dplyr'\n",
       "\\item 'performance'\n",
       "\\item 'readr'\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'parallel'\n",
       "\\item 'pwr'\n",
       "\\item 'dplyr'\n",
       "\\item 'performance'\n",
       "\\item 'readr'\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'stringr'\n",
       "\\item 'parallel'\n",
       "\\item 'pwr'\n",
       "\\item 'dplyr'\n",
       "\\item 'performance'\n",
       "\\item 'readr'\n",
       "\\item 'lme4'\n",
       "\\item 'Matrix'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 1. 'lme4'\n",
       "2. 'Matrix'\n",
       "3. 'stats'\n",
       "4. 'graphics'\n",
       "5. 'grDevices'\n",
       "6. 'utils'\n",
       "7. 'datasets'\n",
       "8. 'methods'\n",
       "9. 'base'\n",
       "\n",
       "\n",
       "\n",
       "2. 1. 'readr'\n",
       "2. 'lme4'\n",
       "3. 'Matrix'\n",
       "4. 'stats'\n",
       "5. 'graphics'\n",
       "6. 'grDevices'\n",
       "7. 'utils'\n",
       "8. 'datasets'\n",
       "9. 'methods'\n",
       "10. 'base'\n",
       "\n",
       "\n",
       "\n",
       "3. 1. 'performance'\n",
       "2. 'readr'\n",
       "3. 'lme4'\n",
       "4. 'Matrix'\n",
       "5. 'stats'\n",
       "6. 'graphics'\n",
       "7. 'grDevices'\n",
       "8. 'utils'\n",
       "9. 'datasets'\n",
       "10. 'methods'\n",
       "11. 'base'\n",
       "\n",
       "\n",
       "\n",
       "4. 1. 'dplyr'\n",
       "2. 'performance'\n",
       "3. 'readr'\n",
       "4. 'lme4'\n",
       "5. 'Matrix'\n",
       "6. 'stats'\n",
       "7. 'graphics'\n",
       "8. 'grDevices'\n",
       "9. 'utils'\n",
       "10. 'datasets'\n",
       "11. 'methods'\n",
       "12. 'base'\n",
       "\n",
       "\n",
       "\n",
       "5. 1. 'pwr'\n",
       "2. 'dplyr'\n",
       "3. 'performance'\n",
       "4. 'readr'\n",
       "5. 'lme4'\n",
       "6. 'Matrix'\n",
       "7. 'stats'\n",
       "8. 'graphics'\n",
       "9. 'grDevices'\n",
       "10. 'utils'\n",
       "11. 'datasets'\n",
       "12. 'methods'\n",
       "13. 'base'\n",
       "\n",
       "\n",
       "\n",
       "6. 1. 'parallel'\n",
       "2. 'pwr'\n",
       "3. 'dplyr'\n",
       "4. 'performance'\n",
       "5. 'readr'\n",
       "6. 'lme4'\n",
       "7. 'Matrix'\n",
       "8. 'stats'\n",
       "9. 'graphics'\n",
       "10. 'grDevices'\n",
       "11. 'utils'\n",
       "12. 'datasets'\n",
       "13. 'methods'\n",
       "14. 'base'\n",
       "\n",
       "\n",
       "\n",
       "7. 1. 'stringr'\n",
       "2. 'parallel'\n",
       "3. 'pwr'\n",
       "4. 'dplyr'\n",
       "5. 'performance'\n",
       "6. 'readr'\n",
       "7. 'lme4'\n",
       "8. 'Matrix'\n",
       "9. 'stats'\n",
       "10. 'graphics'\n",
       "11. 'grDevices'\n",
       "12. 'utils'\n",
       "13. 'datasets'\n",
       "14. 'methods'\n",
       "15. 'base'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] \"lme4\"      \"Matrix\"    \"stats\"     \"graphics\"  \"grDevices\" \"utils\"    \n",
       "[7] \"datasets\"  \"methods\"   \"base\"     \n",
       "\n",
       "[[2]]\n",
       " [1] \"readr\"     \"lme4\"      \"Matrix\"    \"stats\"     \"graphics\"  \"grDevices\"\n",
       " [7] \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n",
       "\n",
       "[[3]]\n",
       " [1] \"performance\" \"readr\"       \"lme4\"        \"Matrix\"      \"stats\"      \n",
       " [6] \"graphics\"    \"grDevices\"   \"utils\"       \"datasets\"    \"methods\"    \n",
       "[11] \"base\"       \n",
       "\n",
       "[[4]]\n",
       " [1] \"dplyr\"       \"performance\" \"readr\"       \"lme4\"        \"Matrix\"     \n",
       " [6] \"stats\"       \"graphics\"    \"grDevices\"   \"utils\"       \"datasets\"   \n",
       "[11] \"methods\"     \"base\"       \n",
       "\n",
       "[[5]]\n",
       " [1] \"pwr\"         \"dplyr\"       \"performance\" \"readr\"       \"lme4\"       \n",
       " [6] \"Matrix\"      \"stats\"       \"graphics\"    \"grDevices\"   \"utils\"      \n",
       "[11] \"datasets\"    \"methods\"     \"base\"       \n",
       "\n",
       "[[6]]\n",
       " [1] \"parallel\"    \"pwr\"         \"dplyr\"       \"performance\" \"readr\"      \n",
       " [6] \"lme4\"        \"Matrix\"      \"stats\"       \"graphics\"    \"grDevices\"  \n",
       "[11] \"utils\"       \"datasets\"    \"methods\"     \"base\"       \n",
       "\n",
       "[[7]]\n",
       " [1] \"stringr\"     \"parallel\"    \"pwr\"         \"dplyr\"       \"performance\"\n",
       " [6] \"readr\"       \"lme4\"        \"Matrix\"      \"stats\"       \"graphics\"   \n",
       "[11] \"grDevices\"   \"utils\"       \"datasets\"    \"methods\"     \"base\"       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "R version 4.3.3 (2024-02-29)\n",
       "Platform: aarch64-apple-darwin20.0.0 (64-bit)\n",
       "Running under: macOS 15.5\n",
       "\n",
       "Matrix products: default\n",
       "BLAS/LAPACK: /Users/zory/miniforge3/envs/py310/lib/libopenblas.0.dylib;  LAPACK version 3.12.0\n",
       "\n",
       "locale:\n",
       "[1] C\n",
       "\n",
       "time zone: America/Los_Angeles\n",
       "tzcode source: system (macOS)\n",
       "\n",
       "attached base packages:\n",
       "[1] parallel  stats     graphics  grDevices utils     datasets  methods  \n",
       "[8] base     \n",
       "\n",
       "other attached packages:\n",
       "[1] broom.mixed_0.2.9.7 parallelly_1.44.0   stringr_1.5.1      \n",
       "[4] pwr_1.3-0           dplyr_1.1.4         performance_0.14.0 \n",
       "[7] readr_2.1.5         lme4_1.1-35.5       Matrix_1.6-5       \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] future_1.49.0     generics_0.1.4    tidyr_1.3.1       stringi_1.8.7    \n",
       " [5] lattice_0.22-6    listenv_0.9.1     hms_1.1.3         digest_0.6.37    \n",
       " [9] magrittr_2.0.3    evaluate_0.22     grid_4.3.3        pbdZMQ_0.3-14    \n",
       "[13] fastmap_1.2.0     jsonlite_2.0.0    backports_1.5.0   purrr_1.0.4      \n",
       "[17] codetools_0.2-20  cli_3.6.4         rlang_1.1.5       crayon_1.5.3     \n",
       "[21] splines_4.3.3     base64enc_0.1-3   repr_1.1.6        tools_4.3.3      \n",
       "[25] tzdb_0.5.0        uuid_1.2-1        nloptr_2.2.1      minqa_1.2.8      \n",
       "[29] forcats_1.0.0     boot_1.3-31       globals_0.18.0    broom_1.0.8      \n",
       "[33] IRdisplay_1.1     vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4  \n",
       "[37] MASS_7.3-60.0.1   furrr_0.3.1       insight_1.3.0     pkgconfig_2.0.3  \n",
       "[41] pillar_1.10.2     glue_1.8.0        Rcpp_1.0.14       tibble_3.2.1     \n",
       "[45] tidyselect_1.2.1  IRkernel_1.3.2    htmltools_0.5.8.1 nlme_3.1-168     \n",
       "[49] compiler_4.3.3   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn=2, error=recover)\n",
    "install_if_missing <- function(pkg, github = NULL) {\n",
    "  if (!requireNamespace(pkg, quietly = TRUE)) {\n",
    "    message(sprintf(\"Installing package: %s\", pkg))\n",
    "    tryCatch({\n",
    "      if (is.null(github)) {\n",
    "        install.packages(pkg, repos = \"https://cloud.r-project.org\")\n",
    "      } else {\n",
    "        if (!requireNamespace(\"remotes\", quietly = TRUE)) {\n",
    "          install.packages(\"remotes\", repos = \"https://cloud.r-project.org\")\n",
    "        }\n",
    "        remotes::install_github(github)\n",
    "      }\n",
    "    }, error = function(e) {\n",
    "      message(sprintf(\"Failed to install %s: %s\", pkg, e$message))\n",
    "      return(NULL)\n",
    "    })\n",
    "  }\n",
    "  if (requireNamespace(pkg, quietly = TRUE)) {\n",
    "    library(pkg, character.only = TRUE)\n",
    "  } else {\n",
    "    message(sprintf(\"Package %s is still not available after attempted installation.\", pkg))\n",
    "  }\n",
    "}\n",
    "pkgs <- c(\"lme4\",\"readr\",\"performance\",\"dplyr\",\"pwr\", \"parallel\", \"stringr\")\n",
    "lapply(pkgs, function(pkg){\n",
    "  install_if_missing(pkg)\n",
    "})\n",
    "install_if_missing(\"parallelly\", github = \"futureverse/parallelly\")\n",
    "install_if_missing(\"broom.mixed\", github = \"bbolker/broom.mixed\")\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627c52ba",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m156825\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m--\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m--------------------------------------------------------\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Run_ID, Part\n",
      "\u001b[32mint\u001b[39m (2): Proximity, n_candidates\n",
      "\u001b[33mlgl\u001b[39m (1): Accuracy\n",
      "\u001b[31mfct\u001b[39m (9): Stimulus_ID, Prompt_ID, Participant_ID, Group, GroupKind, Angle, Ac...\n",
      "\n",
      "\u001b[36mi\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mi\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "df <- read_csv(\"result_1743457603_20250506_20250506F.csv\", na = \"empty\", col_select = c(\"Accuracy\", \"Group\", \"GroupKind\", \"Angle\", \"Proximity\", \"n_candidates\", \"Actor\", \"Candidates\", \"Stimulus_ID\", \"Prompt_ID\", \"Participant_ID\", \"list_id\", \"Run_ID\", \"Part\"), col_types = cols(\n",
    "    Accuracy = col_logical(),\n",
    "    Group = col_factor(),\n",
    "    GroupKind = col_factor(),\n",
    "    Angle = col_factor(c('front', 'left', 'right')),\n",
    "    Proximity = col_integer(),\n",
    "    n_candidates = col_integer(),\n",
    "    Actor = col_factor(c('X', 'Y')),\n",
    "    Candidates = col_factor(),\n",
    "    Stimulus_ID = col_factor(),\n",
    "    Prompt_ID = col_factor(),\n",
    "    Participant_ID = col_factor(),\n",
    "    list_id = col_factor(),\n",
    "    Run_ID = col_character(),\n",
    "    Part = col_character(),\n",
    "),show_col_types = TRUE)\n",
    "df <- df %>% mutate(\n",
    "  offset = log(1/n_candidates / (1 - 1/n_candidates))\n",
    ")\n",
    "\n",
    "GROUP_LIST <- c(\n",
    "  \"Humans\",\n",
    "  \"glm-4v-9b\",\n",
    "  \"gemini-1.5-pro\",\n",
    "  \"gpt-4o\",\n",
    "  \"Qwen2.5-VL-72B-Instruct\",\n",
    "  \"internlm-xcomposer2-vl-7b\"\n",
    ")\n",
    "\n",
    "api_to_name <- list(\n",
    "  \"Humans\" = \"Humans\",\n",
    "  \"gemini-1.5-pro\" = \"Gemini\",\n",
    "  \"gpt-4o\" = \"GPT\",\n",
    "  \"Qwen2.5-VL-72B-Instruct\" = \"Qwen\",\n",
    "  \"internlm-xcomposer2-vl-7b\" = \"InternLM\",\n",
    "  \"glm-4v-9b\" = \"GLM\"\n",
    ")\n",
    "\n",
    "n_stimuli <- 900\n",
    "n_prompts <- 12  # for VLMs\n",
    "n_reps <- 10     # 10 repetitions per stimulus for VLMs\n",
    "n_participants <- 65  # for humans\n",
    "n_trials <- 45  # 45 trials per participant for humans\n",
    "total_trials_vlm <- n_stimuli * n_reps\n",
    "total_trials_human <- n_participants * n_trials  # 65 participants × 45 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3d89df",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "get_formula <- function(grp){\n",
    "  re <- if (grp==\"Humans\") {\n",
    "    \"(1 | Stimulus_ID) + (1 | Participant_ID)\"\n",
    "  } else if (grp %in% c(\"gemini-1.5-pro\",\"Qwen2.5-VL-72B-Instruct\")) {\n",
    "    \"(1 | Stimulus_ID) + (1 | Prompt_ID)\"\n",
    "  } else {\n",
    "    \"(1 | Stimulus_ID)\"\n",
    "  }\n",
    "  as.formula(paste0(\n",
    "    \"Accuracy ~ Angle + scale(Proximity, scale=FALSE)\",\n",
    "    \" + scale(n_candidates, scale=FALSE) + Actor + offset(offset) + \",\n",
    "    re\n",
    "  ))\n",
    "}\n",
    "\n",
    "models <- list()\n",
    "for (grp in GROUP_LIST) {\n",
    "  models[[grp]] <- lme4::glmer(\n",
    "    get_formula(grp),\n",
    "    data = df %>% filter(Group==grp, list_id!=\"-1\", Part!=\"p0\"),\n",
    "    family = binomial(link=\"logit\")\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82bd7c",
   "metadata": {},
   "source": [
    "# Extract ICC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b951be",
   "metadata": {},
   "source": [
    "icc(Stimulus_ID) = expected correlation of two randomly drawn observations from the same stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a6dc30",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A icc_by_group: 9 x 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Group</th><th scope=col>ICC</th><th scope=col>Model</th><th scope=col>Original_Group</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Stimulus_ID   </td><td>0.426272885</td><td>Humans  </td><td>Humans                   </td></tr>\n",
       "\t<tr><td>Participant_ID</td><td>0.062713402</td><td>Humans  </td><td>Humans                   </td></tr>\n",
       "\t<tr><td>Stimulus_ID   </td><td>0.884636603</td><td>GLM     </td><td>glm-4v-9b                </td></tr>\n",
       "\t<tr><td>Stimulus_ID   </td><td>0.831444885</td><td>Gemini  </td><td>gemini-1.5-pro           </td></tr>\n",
       "\t<tr><td>Prompt_ID     </td><td>0.001253011</td><td>Gemini  </td><td>gemini-1.5-pro           </td></tr>\n",
       "\t<tr><td>Stimulus_ID   </td><td>0.739731872</td><td>GPT     </td><td>gpt-4o                   </td></tr>\n",
       "\t<tr><td>Stimulus_ID   </td><td>0.854037287</td><td>Qwen    </td><td>Qwen2.5-VL-72B-Instruct  </td></tr>\n",
       "\t<tr><td>Prompt_ID     </td><td>0.001569549</td><td>Qwen    </td><td>Qwen2.5-VL-72B-Instruct  </td></tr>\n",
       "\t<tr><td>Stimulus_ID   </td><td>0.901237990</td><td>InternLM</td><td>internlm-xcomposer2-vl-7b</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A icc\\_by\\_group: 9 x 4\n",
       "\\begin{tabular}{llll}\n",
       " Group & ICC & Model & Original\\_Group\\\\\n",
       " <chr> & <dbl> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t Stimulus\\_ID    & 0.426272885 & Humans   & Humans                   \\\\\n",
       "\t Participant\\_ID & 0.062713402 & Humans   & Humans                   \\\\\n",
       "\t Stimulus\\_ID    & 0.884636603 & GLM      & glm-4v-9b                \\\\\n",
       "\t Stimulus\\_ID    & 0.831444885 & Gemini   & gemini-1.5-pro           \\\\\n",
       "\t Prompt\\_ID      & 0.001253011 & Gemini   & gemini-1.5-pro           \\\\\n",
       "\t Stimulus\\_ID    & 0.739731872 & GPT      & gpt-4o                   \\\\\n",
       "\t Stimulus\\_ID    & 0.854037287 & Qwen     & Qwen2.5-VL-72B-Instruct  \\\\\n",
       "\t Prompt\\_ID      & 0.001569549 & Qwen     & Qwen2.5-VL-72B-Instruct  \\\\\n",
       "\t Stimulus\\_ID    & 0.901237990 & InternLM & internlm-xcomposer2-vl-7b\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A icc_by_group: 9 x 4\n",
       "\n",
       "| Group &lt;chr&gt; | ICC &lt;dbl&gt; | Model &lt;chr&gt; | Original_Group &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| Stimulus_ID    | 0.426272885 | Humans   | Humans                    |\n",
       "| Participant_ID | 0.062713402 | Humans   | Humans                    |\n",
       "| Stimulus_ID    | 0.884636603 | GLM      | glm-4v-9b                 |\n",
       "| Stimulus_ID    | 0.831444885 | Gemini   | gemini-1.5-pro            |\n",
       "| Prompt_ID      | 0.001253011 | Gemini   | gemini-1.5-pro            |\n",
       "| Stimulus_ID    | 0.739731872 | GPT      | gpt-4o                    |\n",
       "| Stimulus_ID    | 0.854037287 | Qwen     | Qwen2.5-VL-72B-Instruct   |\n",
       "| Prompt_ID      | 0.001569549 | Qwen     | Qwen2.5-VL-72B-Instruct   |\n",
       "| Stimulus_ID    | 0.901237990 | InternLM | internlm-xcomposer2-vl-7b |\n",
       "\n"
      ],
      "text/plain": [
       "  Group          ICC         Model    Original_Group           \n",
       "1 Stimulus_ID    0.426272885 Humans   Humans                   \n",
       "2 Participant_ID 0.062713402 Humans   Humans                   \n",
       "3 Stimulus_ID    0.884636603 GLM      glm-4v-9b                \n",
       "4 Stimulus_ID    0.831444885 Gemini   gemini-1.5-pro           \n",
       "5 Prompt_ID      0.001253011 Gemini   gemini-1.5-pro           \n",
       "6 Stimulus_ID    0.739731872 GPT      gpt-4o                   \n",
       "7 Stimulus_ID    0.854037287 Qwen     Qwen2.5-VL-72B-Instruct  \n",
       "8 Prompt_ID      0.001569549 Qwen     Qwen2.5-VL-72B-Instruct  \n",
       "9 Stimulus_ID    0.901237990 InternLM internlm-xcomposer2-vl-7b"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_icc_performance <- function(models_list, name_map) {\n",
    "  icc_list <- lapply(names(models_list), function(model_key) {\n",
    "    model <- models_list[[model_key]]\n",
    "    \n",
    "    # Calculate ICC using performance::icc() with by_group = TRUE\n",
    "    icc_output <- tryCatch({\n",
    "      performance::icc(model, by_group = TRUE) # Get ICC for each random effect\n",
    "    }, error = function(e) {\n",
    "      message(sprintf(\"Error calculating ICC for model %s: %s\", model_key, e$message))\n",
    "      # Return a data frame with expected columns from by_group = TRUE output\n",
    "      return(data.frame(Group = character(0), ICC = numeric(0))) \n",
    "    })\n",
    "    \n",
    "    # Add the descriptive model name and original group key\n",
    "    # This will apply to all rows in icc_output (if any)\n",
    "    # If icc_output has 0 rows, this will result in a 0-row df with the new columns\n",
    "    # (which is standard dplyr behavior)\n",
    "    icc_output <- icc_output %>%\n",
    "         mutate(Model = name_map[[model_key]],\n",
    "                Original_Group = model_key) \n",
    "    \n",
    "    return(icc_output)\n",
    "  })\n",
    "  \n",
    "  # Combine all ICC data frames\n",
    "  bind_rows(icc_list)\n",
    "}\n",
    "\n",
    "vc2_df <- get_icc_performance(models, api_to_name) # Pass api_to_name here\n",
    "vc2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685523cf",
   "metadata": {},
   "source": [
    "# Analytic (approximation only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea0d2ab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "calculate_effective_n <- function(total_n, cluster_size, icc) {\n",
    "  # Design effect due to clustering\n",
    "  design_effect <- 1 + (cluster_size - 1) * icc\n",
    "  effective_n <- total_n / design_effect\n",
    "  return(effective_n)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3112bb0f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample sizes (adjusted primarily for Stimulus_ID clustering):\n",
      "Model: Humans\n",
      "  Total N: 2925\n",
      "  ICC (Stimulus_ID): 0.4263\n",
      "  Cluster Size (Stimulus_ID): 3.25\n",
      "  Effective N: 1493.02\n",
      "  Other ICCs:\n",
      "    Participant_ID: 0.0627\n",
      "\n",
      "Model: GLM\n",
      "  Total N: 9000\n",
      "  ICC (Stimulus_ID): 0.8846\n",
      "  Cluster Size (Stimulus_ID): 10.00\n",
      "  Effective N: 1004.27\n",
      "  No other ICCs available.\n",
      "\n",
      "Model: Gemini\n",
      "  Total N: 9000\n",
      "  ICC (Stimulus_ID): 0.8314\n",
      "  Cluster Size (Stimulus_ID): 10.00\n",
      "  Effective N: 1060.94\n",
      "  Other ICCs:\n",
      "    Prompt_ID: 0.0013\n",
      "\n",
      "Model: GPT\n",
      "  Total N: 9000\n",
      "  ICC (Stimulus_ID): 0.7397\n",
      "  Cluster Size (Stimulus_ID): 10.00\n",
      "  Effective N: 1175.30\n",
      "  No other ICCs available.\n",
      "\n",
      "Model: Qwen\n",
      "  Total N: 9000\n",
      "  ICC (Stimulus_ID): 0.8540\n",
      "  Cluster Size (Stimulus_ID): 10.00\n",
      "  Effective N: 1036.11\n",
      "  Other ICCs:\n",
      "    Prompt_ID: 0.0016\n",
      "\n",
      "Model: InternLM\n",
      "  Total N: 9000\n",
      "  ICC (Stimulus_ID): 0.9012\n",
      "  Cluster Size (Stimulus_ID): 10.00\n",
      "  Effective N: 987.80\n",
      "  No other ICCs available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure vc2_df is available from previous cells, containing columns:\n",
    "# 'Original_Group' (e.g., \"Humans\", \"gpt-4o\"), 'Group' (random effect, e.g., \"Stimulus_ID\"), 'ICC'\n",
    "\n",
    "effective_n_results <- list()\n",
    "\n",
    "if (!exists(\"vc2_df\")) {\n",
    "  stop(\"Error: vc2_df is not found. Please ensure it's created in a preceding cell.\")\n",
    "}\n",
    "if (!exists(\"calculate_effective_n\")) {\n",
    "  stop(\"Error: calculate_effective_n function is not found. Please ensure it's defined.\")\n",
    "}\n",
    "\n",
    "for (grp_key in GROUP_LIST) {\n",
    "  model_name <- api_to_name[[grp_key]]\n",
    "  \n",
    "  # Get ICC for Stimulus_ID for this model\n",
    "  icc_stimulus_row <- vc2_df %>% filter(Original_Group == grp_key, Group == \"Stimulus_ID\")\n",
    "  \n",
    "  if (nrow(icc_stimulus_row) == 0) {\n",
    "    message(sprintf(\"Warning: ICC for Stimulus_ID not found for group %s (Model: %s). Skipping N_eff calculation.\", grp_key, model_name))\n",
    "    effective_n_results[[grp_key]] <- list(\n",
    "      model_name = model_name,\n",
    "      total_n = NA,\n",
    "      icc_stimulus = NA,\n",
    "      cluster_size_stimulus = NA,\n",
    "      eff_n = NA,\n",
    "      other_iccs = NULL,\n",
    "      notes = \"ICC for Stimulus_ID not found.\"\n",
    "    )\n",
    "    next\n",
    "  }\n",
    "  icc_S <- icc_stimulus_row$ICC[1] # Take the first if multiple (should be unique)\n",
    "  \n",
    "  total_n <- 0\n",
    "  cluster_size_S <- 0\n",
    "  \n",
    "  if (grp_key == \"Humans\") {\n",
    "    total_n <- total_trials_human\n",
    "    cluster_size_S <- total_trials_human / n_stimuli # Avg trials per stimulus for humans\n",
    "  } else { # VLMs\n",
    "    total_n <- total_trials_vlm\n",
    "    cluster_size_S <- n_reps # Repetitions per stimulus for VLMs\n",
    "  }\n",
    "  \n",
    "  eff_n <- calculate_effective_n(total_n, cluster_size_S, icc_S)\n",
    "  \n",
    "  # Store other ICCs for context\n",
    "  other_iccs_df <- vc2_df %>% filter(Original_Group == grp_key, Group != \"Stimulus_ID\")\n",
    "  other_iccs_list <- if(nrow(other_iccs_df) > 0) setNames(as.list(other_iccs_df$ICC), other_iccs_df$Group) else list()\n",
    "  \n",
    "  effective_n_results[[grp_key]] <- list(\n",
    "    model_name = model_name,\n",
    "    total_n = total_n,\n",
    "    icc_stimulus = icc_S,\n",
    "    cluster_size_stimulus = cluster_size_S,\n",
    "    eff_n = eff_n,\n",
    "    other_iccs = other_iccs_list\n",
    "  )\n",
    "}\n",
    "\n",
    "# Print effective sample sizes\n",
    "cat(\"Effective sample sizes (adjusted primarily for Stimulus_ID clustering):\\n\")\n",
    "for (grp_key in GROUP_LIST) {\n",
    "  result <- effective_n_results[[grp_key]]\n",
    "  cat(sprintf(\"Model: %s\\n\", result$model_name))\n",
    "  cat(sprintf(\"  Total N: %d\\n\", result$total_n))\n",
    "  cat(sprintf(\"  ICC (Stimulus_ID): %.4f\\n\", result$icc_stimulus))\n",
    "  cat(sprintf(\"  Cluster Size (Stimulus_ID): %.2f\\n\", result$cluster_size_stimulus))\n",
    "  cat(sprintf(\"  Effective N: %.2f\\n\", result$eff_n))\n",
    "  \n",
    "  if (length(result$other_iccs) > 0) {\n",
    "    cat(\"  Other ICCs:\\n\")\n",
    "    for (group in names(result$other_iccs)) {\n",
    "      cat(sprintf(\"    %s: %.4f\\n\", group, result$other_iccs[[group]]))\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"  No other ICCs available.\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed73419",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Analytical Power Analysis Table (based on N_eff from Stimulus_ID ICC):\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 x 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Model</th><th scope=col>Original_Group</th><th scope=col>Cohens_d</th><th scope=col>Logit_coefficient</th><th scope=col>Power</th><th scope=col>N_eff_total</th><th scope=col>N_per_comparison_group</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>Humans</td><td>Humans</td><td>0.05</td><td>0.09068997</td><td>0.1616871</td><td>1493.022</td><td>746.5109</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>Humans</td><td>Humans</td><td>0.06</td><td>0.10882796</td><td>0.2123241</td><td>1493.022</td><td>746.5109</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>Humans</td><td>Humans</td><td>0.07</td><td>0.12696596</td><td>0.2719094</td><td>1493.022</td><td>746.5109</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>Humans</td><td>Humans</td><td>0.08</td><td>0.14510395</td><td>0.3391628</td><td>1493.022</td><td>746.5109</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>Humans</td><td>Humans</td><td>0.09</td><td>0.16324194</td><td>0.4121489</td><td>1493.022</td><td>746.5109</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>Humans</td><td>Humans</td><td>0.10</td><td>0.18137994</td><td>0.4883920</td><td>1493.022</td><td>746.5109</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 x 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & Model & Original\\_Group & Cohens\\_d & Logit\\_coefficient & Power & N\\_eff\\_total & N\\_per\\_comparison\\_group\\\\\n",
       "  & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & Humans & Humans & 0.05 & 0.09068997 & 0.1616871 & 1493.022 & 746.5109\\\\\n",
       "\t2 & Humans & Humans & 0.06 & 0.10882796 & 0.2123241 & 1493.022 & 746.5109\\\\\n",
       "\t3 & Humans & Humans & 0.07 & 0.12696596 & 0.2719094 & 1493.022 & 746.5109\\\\\n",
       "\t4 & Humans & Humans & 0.08 & 0.14510395 & 0.3391628 & 1493.022 & 746.5109\\\\\n",
       "\t5 & Humans & Humans & 0.09 & 0.16324194 & 0.4121489 & 1493.022 & 746.5109\\\\\n",
       "\t6 & Humans & Humans & 0.10 & 0.18137994 & 0.4883920 & 1493.022 & 746.5109\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 x 7\n",
       "\n",
       "| <!--/--> | Model &lt;chr&gt; | Original_Group &lt;chr&gt; | Cohens_d &lt;dbl&gt; | Logit_coefficient &lt;dbl&gt; | Power &lt;dbl&gt; | N_eff_total &lt;dbl&gt; | N_per_comparison_group &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | Humans | Humans | 0.05 | 0.09068997 | 0.1616871 | 1493.022 | 746.5109 |\n",
       "| 2 | Humans | Humans | 0.06 | 0.10882796 | 0.2123241 | 1493.022 | 746.5109 |\n",
       "| 3 | Humans | Humans | 0.07 | 0.12696596 | 0.2719094 | 1493.022 | 746.5109 |\n",
       "| 4 | Humans | Humans | 0.08 | 0.14510395 | 0.3391628 | 1493.022 | 746.5109 |\n",
       "| 5 | Humans | Humans | 0.09 | 0.16324194 | 0.4121489 | 1493.022 | 746.5109 |\n",
       "| 6 | Humans | Humans | 0.10 | 0.18137994 | 0.4883920 | 1493.022 | 746.5109 |\n",
       "\n"
      ],
      "text/plain": [
       "  Model  Original_Group Cohens_d Logit_coefficient Power     N_eff_total\n",
       "1 Humans Humans         0.05     0.09068997        0.1616871 1493.022   \n",
       "2 Humans Humans         0.06     0.10882796        0.2123241 1493.022   \n",
       "3 Humans Humans         0.07     0.12696596        0.2719094 1493.022   \n",
       "4 Humans Humans         0.08     0.14510395        0.3391628 1493.022   \n",
       "5 Humans Humans         0.09     0.16324194        0.4121489 1493.022   \n",
       "6 Humans Humans         0.10     0.18137994        0.4883920 1493.022   \n",
       "  N_per_comparison_group\n",
       "1 746.5109              \n",
       "2 746.5109              \n",
       "3 746.5109              \n",
       "4 746.5109              \n",
       "5 746.5109              \n",
       "6 746.5109              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_to_logit <- function(d) {\n",
    "  # Convert Cohen's d back to logit coefficient\n",
    "  return(d * pi / sqrt(3))\n",
    "}\n",
    "\n",
    "# Calculate power for different effect sizes\n",
    "effect_sizes_d <- seq(0.05, 0.5, by = 0.01)  # Cohen's d scale\n",
    "all_power_results <- list()\n",
    "\n",
    "if (!exists(\"effective_n_results\")) {\n",
    "  stop(\"Error: 'effective_n_results' not found. Run the previous cell.\")\n",
    "}\n",
    "\n",
    "for (grp_key in names(effective_n_results)) {\n",
    "  res <- effective_n_results[[grp_key]]\n",
    "  current_eff_n <- res$eff_n\n",
    "  \n",
    "  if (is.na(current_eff_n) || current_eff_n <= 0) {\n",
    "      message(sprintf(\"Skipping power calculation for %s (%s) due to invalid N_eff (%.1f)\", res$model_name, grp_key, current_eff_n))\n",
    "      next\n",
    "  }\n",
    "  \n",
    "  # n for pwr.t.test is sample size per group for a two-sample t-test.\n",
    "  # We assume current_eff_n is the total effective N for the model/group,\n",
    "  # and the comparison of interest (e.g., factor level) involves splitting this into two sub-groups.\n",
    "  sample_size_per_comparison_group <- current_eff_n / 2\n",
    "  \n",
    "  power_values <- numeric(length(effect_sizes_d))\n",
    "  if (sample_size_per_comparison_group < 2) { # pwr.t.test requires n >= 2\n",
    "      message(sprintf(\"Effective sample size per comparison group for %s (%.1f) is < 2. Power set to 0.\", res$model_name, sample_size_per_comparison_group))\n",
    "      power_values <- rep(0, length(effect_sizes_d))\n",
    "  } else {\n",
    "      power_values <- sapply(effect_sizes_d, function(d) {\n",
    "        tryCatch({\n",
    "          pwr.t.test(n = sample_size_per_comparison_group, d = d, sig.level = 0.05, type = \"two.sample\")$power\n",
    "        }, error = function(e) { 0 }) # Default to 0 power on error\n",
    "      })\n",
    "  }\n",
    "  \n",
    "  power_df_grp <- data.frame(\n",
    "    Model = res$model_name,\n",
    "    Original_Group = grp_key,\n",
    "    Cohens_d = effect_sizes_d,\n",
    "    Logit_coefficient = d_to_logit(effect_sizes_d),\n",
    "    Power = power_values,\n",
    "    N_eff_total = current_eff_n,\n",
    "    N_per_comparison_group = sample_size_per_comparison_group\n",
    "  )\n",
    "  all_power_results[[grp_key]] <- power_df_grp\n",
    "}\n",
    "\n",
    "power_table_analytic <- do.call(rbind, all_power_results)\n",
    "if (!is.null(power_table_analytic)) {\n",
    "  rownames(power_table_analytic) <- NULL\n",
    "}\n",
    "\n",
    "print(\"Analytical Power Analysis Table (based on N_eff from Stimulus_ID ICC):\")\n",
    "head(power_table_analytic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd27f92",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Minimum Detectable Effect Sizes (80% Power, Analytic Approximation):\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 x 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Model</th><th scope=col>Original_Group</th><th scope=col>N_eff_total</th><th scope=col>N_per_comparison_group</th><th scope=col>Min_Cohens_d</th><th scope=col>Min_Logit_Coeff</th><th scope=col>Power_at_Min_d</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>GLM     </td><td>glm-4v-9b                </td><td>1004.2704</td><td>502.1352</td><td>0.18</td><td>0.3264839</td><td>0.8131127</td></tr>\n",
       "\t<tr><td>GPT     </td><td>gpt-4o                   </td><td>1175.3050</td><td>587.6525</td><td>0.17</td><td>0.3083459</td><td>0.8293712</td></tr>\n",
       "\t<tr><td>Gemini  </td><td>gemini-1.5-pro           </td><td>1060.9449</td><td>530.4725</td><td>0.18</td><td>0.3264839</td><td>0.8336954</td></tr>\n",
       "\t<tr><td>Humans  </td><td>Humans                   </td><td>1493.0219</td><td>746.5109</td><td>0.15</td><td>0.2720699</td><td>0.8254006</td></tr>\n",
       "\t<tr><td>InternLM</td><td>internlm-xcomposer2-vl-7b</td><td> 987.8015</td><td>493.9008</td><td>0.18</td><td>0.3264839</td><td>0.8067331</td></tr>\n",
       "\t<tr><td>Qwen    </td><td>Qwen2.5-VL-72B-Instruct  </td><td>1036.1101</td><td>518.0550</td><td>0.18</td><td>0.3264839</td><td>0.8249323</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 x 7\n",
       "\\begin{tabular}{lllllll}\n",
       " Model & Original\\_Group & N\\_eff\\_total & N\\_per\\_comparison\\_group & Min\\_Cohens\\_d & Min\\_Logit\\_Coeff & Power\\_at\\_Min\\_d\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t GLM      & glm-4v-9b                 & 1004.2704 & 502.1352 & 0.18 & 0.3264839 & 0.8131127\\\\\n",
       "\t GPT      & gpt-4o                    & 1175.3050 & 587.6525 & 0.17 & 0.3083459 & 0.8293712\\\\\n",
       "\t Gemini   & gemini-1.5-pro            & 1060.9449 & 530.4725 & 0.18 & 0.3264839 & 0.8336954\\\\\n",
       "\t Humans   & Humans                    & 1493.0219 & 746.5109 & 0.15 & 0.2720699 & 0.8254006\\\\\n",
       "\t InternLM & internlm-xcomposer2-vl-7b &  987.8015 & 493.9008 & 0.18 & 0.3264839 & 0.8067331\\\\\n",
       "\t Qwen     & Qwen2.5-VL-72B-Instruct   & 1036.1101 & 518.0550 & 0.18 & 0.3264839 & 0.8249323\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 x 7\n",
       "\n",
       "| Model &lt;chr&gt; | Original_Group &lt;chr&gt; | N_eff_total &lt;dbl&gt; | N_per_comparison_group &lt;dbl&gt; | Min_Cohens_d &lt;dbl&gt; | Min_Logit_Coeff &lt;dbl&gt; | Power_at_Min_d &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| GLM      | glm-4v-9b                 | 1004.2704 | 502.1352 | 0.18 | 0.3264839 | 0.8131127 |\n",
       "| GPT      | gpt-4o                    | 1175.3050 | 587.6525 | 0.17 | 0.3083459 | 0.8293712 |\n",
       "| Gemini   | gemini-1.5-pro            | 1060.9449 | 530.4725 | 0.18 | 0.3264839 | 0.8336954 |\n",
       "| Humans   | Humans                    | 1493.0219 | 746.5109 | 0.15 | 0.2720699 | 0.8254006 |\n",
       "| InternLM | internlm-xcomposer2-vl-7b |  987.8015 | 493.9008 | 0.18 | 0.3264839 | 0.8067331 |\n",
       "| Qwen     | Qwen2.5-VL-72B-Instruct   | 1036.1101 | 518.0550 | 0.18 | 0.3264839 | 0.8249323 |\n",
       "\n"
      ],
      "text/plain": [
       "  Model    Original_Group            N_eff_total N_per_comparison_group\n",
       "1 GLM      glm-4v-9b                 1004.2704   502.1352              \n",
       "2 GPT      gpt-4o                    1175.3050   587.6525              \n",
       "3 Gemini   gemini-1.5-pro            1060.9449   530.4725              \n",
       "4 Humans   Humans                    1493.0219   746.5109              \n",
       "5 InternLM internlm-xcomposer2-vl-7b  987.8015   493.9008              \n",
       "6 Qwen     Qwen2.5-VL-72B-Instruct   1036.1101   518.0550              \n",
       "  Min_Cohens_d Min_Logit_Coeff Power_at_Min_d\n",
       "1 0.18         0.3264839       0.8131127     \n",
       "2 0.17         0.3083459       0.8293712     \n",
       "3 0.18         0.3264839       0.8336954     \n",
       "4 0.15         0.2720699       0.8254006     \n",
       "5 0.18         0.3264839       0.8067331     \n",
       "6 0.18         0.3264839       0.8249323     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary table for minimum detectable effect sizes at 80% power\n",
    "if (!is.null(power_table_analytic) && nrow(power_table_analytic) > 0) {\n",
    "  min_detectable_effects_analytic <- power_table_analytic %>%\n",
    "    filter(!is.na(Power)) %>%\n",
    "    group_by(Model, Original_Group, N_eff_total, N_per_comparison_group) %>%\n",
    "    filter(Power >= 0.80) %>%\n",
    "    slice_min(order_by = Cohens_d, n = 1, with_ties = FALSE) %>%\n",
    "    ungroup() %>%\n",
    "    select(Model, Original_Group, N_eff_total, N_per_comparison_group, Min_Cohens_d = Cohens_d, Min_Logit_Coeff = Logit_coefficient, Power_at_Min_d = Power)\n",
    "  \n",
    "  print(\"Minimum Detectable Effect Sizes (80% Power, Analytic Approximation):\")\n",
    "  min_detectable_effects_analytic\n",
    "} else {\n",
    "  print(\"No models had sufficient data for MDE calculation at 80% power or power_table_analytic is empty.\")\n",
    "  min_detectable_effects_analytic <- data.frame() # Ensure it exists as empty df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32bcf7f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"TOST Equivalence Test Summary:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 30 x 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Model</th><th scope=col>Term</th><th scope=col>Estimate_log_odds</th><th scope=col>Original_P_Value</th><th scope=col>Is_Equivalent_TOST</th><th scope=col>Notes</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Humans  </td><td>ActorY                            </td><td>-1.0032615</td><td>2.554306e-05</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GLM     </td><td>ActorY                            </td><td>-1.3476203</td><td>1.253278e-03</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Gemini  </td><td>ActorY                            </td><td>-0.1659441</td><td>5.978654e-01</td><td> TRUE</td><td>true null   </td></tr>\n",
       "\t<tr><td>GPT     </td><td>ActorY                            </td><td>-0.9381818</td><td>5.638863e-05</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Qwen    </td><td>ActorY                            </td><td>-0.7439780</td><td>3.320191e-02</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>InternLM</td><td>ActorY                            </td><td>-1.1438885</td><td>1.417229e-02</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Humans  </td><td>Angleleft                         </td><td>-3.2358288</td><td>1.678691e-14</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GLM     </td><td>Angleleft                         </td><td>-0.3161462</td><td>5.170334e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>Gemini  </td><td>Angleleft                         </td><td>-0.4442305</td><td>2.440094e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>GPT     </td><td>Angleleft                         </td><td>-0.1698470</td><td>5.437433e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>Qwen    </td><td>Angleleft                         </td><td> 0.5941995</td><td>1.655841e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>InternLM</td><td>Angleleft                         </td><td> 0.1730034</td><td>7.523032e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>Humans  </td><td>Angleright                        </td><td>-3.2180958</td><td>3.132747e-14</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GLM     </td><td>Angleright                        </td><td>-0.2925773</td><td>5.495367e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>Gemini  </td><td>Angleright                        </td><td>-0.2523914</td><td>5.093410e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>GPT     </td><td>Angleright                        </td><td>-0.1262396</td><td>6.502072e-01</td><td> TRUE</td><td>true null   </td></tr>\n",
       "\t<tr><td>Qwen    </td><td>Angleright                        </td><td> 0.4429926</td><td>2.934556e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>InternLM</td><td>Angleright                        </td><td> 0.2448312</td><td>6.551757e-01</td><td>FALSE</td><td>underpowered</td></tr>\n",
       "\t<tr><td>Humans  </td><td>scale(Proximity, scale = FALSE)   </td><td>-1.3047983</td><td>7.299743e-15</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GLM     </td><td>scale(Proximity, scale = FALSE)   </td><td>-0.7257426</td><td>3.560838e-03</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Gemini  </td><td>scale(Proximity, scale = FALSE)   </td><td>-0.7219165</td><td>1.836249e-04</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GPT     </td><td>scale(Proximity, scale = FALSE)   </td><td>-0.4639305</td><td>9.291066e-04</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Qwen    </td><td>scale(Proximity, scale = FALSE)   </td><td>-0.3035033</td><td>1.501018e-01</td><td> TRUE</td><td>true null   </td></tr>\n",
       "\t<tr><td>InternLM</td><td>scale(Proximity, scale = FALSE)   </td><td>-0.6573970</td><td>1.788168e-02</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Humans  </td><td>scale(n_candidates, scale = FALSE)</td><td>-0.6700431</td><td>1.017931e-05</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GLM     </td><td>scale(n_candidates, scale = FALSE)</td><td>-1.4594303</td><td>6.690701e-07</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Gemini  </td><td>scale(n_candidates, scale = FALSE)</td><td>-0.9059379</td><td>1.286017e-05</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>GPT     </td><td>scale(n_candidates, scale = FALSE)</td><td>-0.5870535</td><td>1.211191e-04</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>Qwen    </td><td>scale(n_candidates, scale = FALSE)</td><td>-1.1449311</td><td>8.909797e-07</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "\t<tr><td>InternLM</td><td>scale(n_candidates, scale = FALSE)</td><td>-1.6442912</td><td>6.926775e-07</td><td>FALSE</td><td>meaningful  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 30 x 6\n",
       "\\begin{tabular}{llllll}\n",
       " Model & Term & Estimate\\_log\\_odds & Original\\_P\\_Value & Is\\_Equivalent\\_TOST & Notes\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <lgl> & <chr>\\\\\n",
       "\\hline\n",
       "\t Humans   & ActorY                             & -1.0032615 & 2.554306e-05 & FALSE & meaningful  \\\\\n",
       "\t GLM      & ActorY                             & -1.3476203 & 1.253278e-03 & FALSE & meaningful  \\\\\n",
       "\t Gemini   & ActorY                             & -0.1659441 & 5.978654e-01 &  TRUE & true null   \\\\\n",
       "\t GPT      & ActorY                             & -0.9381818 & 5.638863e-05 & FALSE & meaningful  \\\\\n",
       "\t Qwen     & ActorY                             & -0.7439780 & 3.320191e-02 & FALSE & meaningful  \\\\\n",
       "\t InternLM & ActorY                             & -1.1438885 & 1.417229e-02 & FALSE & meaningful  \\\\\n",
       "\t Humans   & Angleleft                          & -3.2358288 & 1.678691e-14 & FALSE & meaningful  \\\\\n",
       "\t GLM      & Angleleft                          & -0.3161462 & 5.170334e-01 & FALSE & underpowered\\\\\n",
       "\t Gemini   & Angleleft                          & -0.4442305 & 2.440094e-01 & FALSE & underpowered\\\\\n",
       "\t GPT      & Angleleft                          & -0.1698470 & 5.437433e-01 & FALSE & underpowered\\\\\n",
       "\t Qwen     & Angleleft                          &  0.5941995 & 1.655841e-01 & FALSE & underpowered\\\\\n",
       "\t InternLM & Angleleft                          &  0.1730034 & 7.523032e-01 & FALSE & underpowered\\\\\n",
       "\t Humans   & Angleright                         & -3.2180958 & 3.132747e-14 & FALSE & meaningful  \\\\\n",
       "\t GLM      & Angleright                         & -0.2925773 & 5.495367e-01 & FALSE & underpowered\\\\\n",
       "\t Gemini   & Angleright                         & -0.2523914 & 5.093410e-01 & FALSE & underpowered\\\\\n",
       "\t GPT      & Angleright                         & -0.1262396 & 6.502072e-01 &  TRUE & true null   \\\\\n",
       "\t Qwen     & Angleright                         &  0.4429926 & 2.934556e-01 & FALSE & underpowered\\\\\n",
       "\t InternLM & Angleright                         &  0.2448312 & 6.551757e-01 & FALSE & underpowered\\\\\n",
       "\t Humans   & scale(Proximity, scale = FALSE)    & -1.3047983 & 7.299743e-15 & FALSE & meaningful  \\\\\n",
       "\t GLM      & scale(Proximity, scale = FALSE)    & -0.7257426 & 3.560838e-03 & FALSE & meaningful  \\\\\n",
       "\t Gemini   & scale(Proximity, scale = FALSE)    & -0.7219165 & 1.836249e-04 & FALSE & meaningful  \\\\\n",
       "\t GPT      & scale(Proximity, scale = FALSE)    & -0.4639305 & 9.291066e-04 & FALSE & meaningful  \\\\\n",
       "\t Qwen     & scale(Proximity, scale = FALSE)    & -0.3035033 & 1.501018e-01 &  TRUE & true null   \\\\\n",
       "\t InternLM & scale(Proximity, scale = FALSE)    & -0.6573970 & 1.788168e-02 & FALSE & meaningful  \\\\\n",
       "\t Humans   & scale(n\\_candidates, scale = FALSE) & -0.6700431 & 1.017931e-05 & FALSE & meaningful  \\\\\n",
       "\t GLM      & scale(n\\_candidates, scale = FALSE) & -1.4594303 & 6.690701e-07 & FALSE & meaningful  \\\\\n",
       "\t Gemini   & scale(n\\_candidates, scale = FALSE) & -0.9059379 & 1.286017e-05 & FALSE & meaningful  \\\\\n",
       "\t GPT      & scale(n\\_candidates, scale = FALSE) & -0.5870535 & 1.211191e-04 & FALSE & meaningful  \\\\\n",
       "\t Qwen     & scale(n\\_candidates, scale = FALSE) & -1.1449311 & 8.909797e-07 & FALSE & meaningful  \\\\\n",
       "\t InternLM & scale(n\\_candidates, scale = FALSE) & -1.6442912 & 6.926775e-07 & FALSE & meaningful  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 30 x 6\n",
       "\n",
       "| Model &lt;chr&gt; | Term &lt;chr&gt; | Estimate_log_odds &lt;dbl&gt; | Original_P_Value &lt;dbl&gt; | Is_Equivalent_TOST &lt;lgl&gt; | Notes &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| Humans   | ActorY                             | -1.0032615 | 2.554306e-05 | FALSE | meaningful   |\n",
       "| GLM      | ActorY                             | -1.3476203 | 1.253278e-03 | FALSE | meaningful   |\n",
       "| Gemini   | ActorY                             | -0.1659441 | 5.978654e-01 |  TRUE | true null    |\n",
       "| GPT      | ActorY                             | -0.9381818 | 5.638863e-05 | FALSE | meaningful   |\n",
       "| Qwen     | ActorY                             | -0.7439780 | 3.320191e-02 | FALSE | meaningful   |\n",
       "| InternLM | ActorY                             | -1.1438885 | 1.417229e-02 | FALSE | meaningful   |\n",
       "| Humans   | Angleleft                          | -3.2358288 | 1.678691e-14 | FALSE | meaningful   |\n",
       "| GLM      | Angleleft                          | -0.3161462 | 5.170334e-01 | FALSE | underpowered |\n",
       "| Gemini   | Angleleft                          | -0.4442305 | 2.440094e-01 | FALSE | underpowered |\n",
       "| GPT      | Angleleft                          | -0.1698470 | 5.437433e-01 | FALSE | underpowered |\n",
       "| Qwen     | Angleleft                          |  0.5941995 | 1.655841e-01 | FALSE | underpowered |\n",
       "| InternLM | Angleleft                          |  0.1730034 | 7.523032e-01 | FALSE | underpowered |\n",
       "| Humans   | Angleright                         | -3.2180958 | 3.132747e-14 | FALSE | meaningful   |\n",
       "| GLM      | Angleright                         | -0.2925773 | 5.495367e-01 | FALSE | underpowered |\n",
       "| Gemini   | Angleright                         | -0.2523914 | 5.093410e-01 | FALSE | underpowered |\n",
       "| GPT      | Angleright                         | -0.1262396 | 6.502072e-01 |  TRUE | true null    |\n",
       "| Qwen     | Angleright                         |  0.4429926 | 2.934556e-01 | FALSE | underpowered |\n",
       "| InternLM | Angleright                         |  0.2448312 | 6.551757e-01 | FALSE | underpowered |\n",
       "| Humans   | scale(Proximity, scale = FALSE)    | -1.3047983 | 7.299743e-15 | FALSE | meaningful   |\n",
       "| GLM      | scale(Proximity, scale = FALSE)    | -0.7257426 | 3.560838e-03 | FALSE | meaningful   |\n",
       "| Gemini   | scale(Proximity, scale = FALSE)    | -0.7219165 | 1.836249e-04 | FALSE | meaningful   |\n",
       "| GPT      | scale(Proximity, scale = FALSE)    | -0.4639305 | 9.291066e-04 | FALSE | meaningful   |\n",
       "| Qwen     | scale(Proximity, scale = FALSE)    | -0.3035033 | 1.501018e-01 |  TRUE | true null    |\n",
       "| InternLM | scale(Proximity, scale = FALSE)    | -0.6573970 | 1.788168e-02 | FALSE | meaningful   |\n",
       "| Humans   | scale(n_candidates, scale = FALSE) | -0.6700431 | 1.017931e-05 | FALSE | meaningful   |\n",
       "| GLM      | scale(n_candidates, scale = FALSE) | -1.4594303 | 6.690701e-07 | FALSE | meaningful   |\n",
       "| Gemini   | scale(n_candidates, scale = FALSE) | -0.9059379 | 1.286017e-05 | FALSE | meaningful   |\n",
       "| GPT      | scale(n_candidates, scale = FALSE) | -0.5870535 | 1.211191e-04 | FALSE | meaningful   |\n",
       "| Qwen     | scale(n_candidates, scale = FALSE) | -1.1449311 | 8.909797e-07 | FALSE | meaningful   |\n",
       "| InternLM | scale(n_candidates, scale = FALSE) | -1.6442912 | 6.926775e-07 | FALSE | meaningful   |\n",
       "\n"
      ],
      "text/plain": [
       "   Model    Term                               Estimate_log_odds\n",
       "1  Humans   ActorY                             -1.0032615       \n",
       "2  GLM      ActorY                             -1.3476203       \n",
       "3  Gemini   ActorY                             -0.1659441       \n",
       "4  GPT      ActorY                             -0.9381818       \n",
       "5  Qwen     ActorY                             -0.7439780       \n",
       "6  InternLM ActorY                             -1.1438885       \n",
       "7  Humans   Angleleft                          -3.2358288       \n",
       "8  GLM      Angleleft                          -0.3161462       \n",
       "9  Gemini   Angleleft                          -0.4442305       \n",
       "10 GPT      Angleleft                          -0.1698470       \n",
       "11 Qwen     Angleleft                           0.5941995       \n",
       "12 InternLM Angleleft                           0.1730034       \n",
       "13 Humans   Angleright                         -3.2180958       \n",
       "14 GLM      Angleright                         -0.2925773       \n",
       "15 Gemini   Angleright                         -0.2523914       \n",
       "16 GPT      Angleright                         -0.1262396       \n",
       "17 Qwen     Angleright                          0.4429926       \n",
       "18 InternLM Angleright                          0.2448312       \n",
       "19 Humans   scale(Proximity, scale = FALSE)    -1.3047983       \n",
       "20 GLM      scale(Proximity, scale = FALSE)    -0.7257426       \n",
       "21 Gemini   scale(Proximity, scale = FALSE)    -0.7219165       \n",
       "22 GPT      scale(Proximity, scale = FALSE)    -0.4639305       \n",
       "23 Qwen     scale(Proximity, scale = FALSE)    -0.3035033       \n",
       "24 InternLM scale(Proximity, scale = FALSE)    -0.6573970       \n",
       "25 Humans   scale(n_candidates, scale = FALSE) -0.6700431       \n",
       "26 GLM      scale(n_candidates, scale = FALSE) -1.4594303       \n",
       "27 Gemini   scale(n_candidates, scale = FALSE) -0.9059379       \n",
       "28 GPT      scale(n_candidates, scale = FALSE) -0.5870535       \n",
       "29 Qwen     scale(n_candidates, scale = FALSE) -1.1449311       \n",
       "30 InternLM scale(n_candidates, scale = FALSE) -1.6442912       \n",
       "   Original_P_Value Is_Equivalent_TOST Notes       \n",
       "1  2.554306e-05     FALSE              meaningful  \n",
       "2  1.253278e-03     FALSE              meaningful  \n",
       "3  5.978654e-01      TRUE              true null   \n",
       "4  5.638863e-05     FALSE              meaningful  \n",
       "5  3.320191e-02     FALSE              meaningful  \n",
       "6  1.417229e-02     FALSE              meaningful  \n",
       "7  1.678691e-14     FALSE              meaningful  \n",
       "8  5.170334e-01     FALSE              underpowered\n",
       "9  2.440094e-01     FALSE              underpowered\n",
       "10 5.437433e-01     FALSE              underpowered\n",
       "11 1.655841e-01     FALSE              underpowered\n",
       "12 7.523032e-01     FALSE              underpowered\n",
       "13 3.132747e-14     FALSE              meaningful  \n",
       "14 5.495367e-01     FALSE              underpowered\n",
       "15 5.093410e-01     FALSE              underpowered\n",
       "16 6.502072e-01      TRUE              true null   \n",
       "17 2.934556e-01     FALSE              underpowered\n",
       "18 6.551757e-01     FALSE              underpowered\n",
       "19 7.299743e-15     FALSE              meaningful  \n",
       "20 3.560838e-03     FALSE              meaningful  \n",
       "21 1.836249e-04     FALSE              meaningful  \n",
       "22 9.291066e-04     FALSE              meaningful  \n",
       "23 1.501018e-01      TRUE              true null   \n",
       "24 1.788168e-02     FALSE              meaningful  \n",
       "25 1.017931e-05     FALSE              meaningful  \n",
       "26 6.690701e-07     FALSE              meaningful  \n",
       "27 1.286017e-05     FALSE              meaningful  \n",
       "28 1.211191e-04     FALSE              meaningful  \n",
       "29 8.909797e-07     FALSE              meaningful  \n",
       "30 6.926775e-07     FALSE              meaningful  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tost_results <- list()\n",
    "alpha_tost <- 0.05 # Significance level for equivalence testing\n",
    "\n",
    "for (grp_key in names(models)) {\n",
    "  model <- models[[grp_key]]\n",
    "  model_name_descriptive <- api_to_name[[grp_key]]\n",
    "  \n",
    "  # Get model summary for fixed effects\n",
    "  model_summary <- summary(model)$coefficients\n",
    "  model_summary_df <- as.data.frame(model_summary)\n",
    "  model_summary_df$Term <- rownames(model_summary_df)\n",
    "  rownames(model_summary_df) <- NULL\n",
    "  \n",
    "  # Calculate denominator for standardizing coefficients (as you did before)\n",
    "  vc_list <- lapply(lme4::VarCorr(model), function(x) attr(x, \"stddev\")^2)\n",
    "  vc <- sum(unlist(vc_list), na.rm = TRUE) # Added na.rm = TRUE for robustness\n",
    "  effect_size_denom_t <- sqrt(vc + (pi^2/3))\n",
    "  \n",
    "  # Get SESOI (Min_Cohens_d) for this group from the analytical power analysis\n",
    "  mde_row <- min_detectable_effects_analytic %>%\n",
    "    filter(Original_Group == grp_key)\n",
    "  \n",
    "  sesoi_d <- NA\n",
    "  notes_for_group <- \"\"\n",
    "  \n",
    "  if (nrow(mde_row) == 0 || is.na(mde_row$Min_Cohens_d[1])) {\n",
    "    message(sprintf(\"Warning: MDE/SESOI (Min_Cohens_d) not found for group %s (Model: %s). TOST p-values will be NA.\", grp_key, model_name_descriptive))\n",
    "    notes_for_group <- \"MDE/SESOI not available\"\n",
    "  } else {\n",
    "    sesoi_d <- mde_row$Min_Cohens_d[1]\n",
    "  }\n",
    "  \n",
    "  group_tost_results_list <- list()\n",
    "  \n",
    "  for (i in 1:nrow(model_summary_df)) {\n",
    "    term_name <- model_summary_df$Term[i]\n",
    "    estimate_log_odds <- model_summary_df$Estimate[i]\n",
    "    se_log_odds <- model_summary_df$`Std. Error`[i]\n",
    "    original_p_value <- model_summary_df$`Pr(>|z|)`[i]\n",
    "\n",
    "    # Standardize estimate and SE\n",
    "    estimate_std <- estimate_log_odds / effect_size_denom_t\n",
    "    se_std <- se_log_odds / effect_size_denom_t\n",
    "    \n",
    "    p_upper_tost <- NA\n",
    "    p_lower_tost <- NA\n",
    "    p_value_tost <- NA\n",
    "    is_equivalent <- NA\n",
    "    term_notes <- notes_for_group\n",
    "    \n",
    "    if (term_name == \"(Intercept)\") {\n",
    "      term_notes <- paste(notes_for_group, \"TOST not typically applied to intercept\", sep=\"; \")\n",
    "    } else if (is.na(sesoi_d)) {\n",
    "      # Already handled by notes_for_group, is_equivalent remains NA\n",
    "    } else if (is.na(estimate_std) || is.na(se_std) || se_std <= 0) {\n",
    "        term_notes <- paste(notes_for_group, \"Invalid estimate or SE for TOST\", sep=\"; \")\n",
    "    } else {\n",
    "      # Equivalence bounds (symmetric around 0 on the standardized scale)\n",
    "      # We are testing if the effect is within [-sesoi_d, +sesoi_d]\n",
    "      equiv_bound_upper <- sesoi_d\n",
    "      equiv_bound_lower <- -sesoi_d\n",
    "      \n",
    "      # Test 1: Is the effect significantly less than the upper equivalence bound?\n",
    "      # H0: estimate_std >= equiv_bound_upper  vs. H1: estimate_std < equiv_bound_upper\n",
    "      z_upper <- (estimate_std - equiv_bound_upper) / se_std\n",
    "      p_upper_tost <- pnorm(z_upper, lower.tail = TRUE)\n",
    "      \n",
    "      # Test 2: Is the effect significantly greater than the lower equivalence bound?\n",
    "      # H0: estimate_std <= equiv_bound_lower vs. H1: estimate_std > equiv_bound_lower\n",
    "      z_lower <- (estimate_std - equiv_bound_lower) / se_std\n",
    "      p_lower_tost <- pnorm(z_lower, lower.tail = FALSE)\n",
    "      \n",
    "      # For equivalence, both one-sided tests must be significant\n",
    "      p_value_tost <- max(p_upper_tost, p_lower_tost)\n",
    "      is_equivalent <- p_value_tost < alpha_tost\n",
    "    }\n",
    "    \n",
    "    group_tost_results_list[[term_name]] <- data.frame(\n",
    "      Model = model_name_descriptive,\n",
    "      Original_Group = grp_key,\n",
    "      Term = term_name,\n",
    "      Estimate_log_odds = estimate_log_odds,\n",
    "      Std_Error_log_odds = se_log_odds,\n",
    "      Original_P_Value = original_p_value,\n",
    "      Estimate_std = estimate_std, # Standardized effect size (Cohen's d like)\n",
    "      Std_Error_std = se_std,\n",
    "      SESOI_d = sesoi_d,\n",
    "      P_Upper_TOST = p_upper_tost,\n",
    "      P_Lower_TOST = p_lower_tost,\n",
    "      P_Value_TOST = p_value_tost,\n",
    "      Is_Equivalent_TOST = is_equivalent,\n",
    "      Notes = term_notes\n",
    "    )\n",
    "  }\n",
    "  if (length(group_tost_results_list) > 0) {\n",
    "    all_tost_results[[grp_key]] <- do.call(rbind, group_tost_results_list)\n",
    "  }\n",
    "}\n",
    "\n",
    "if (length(all_tost_results) > 0) {\n",
    "  tost_summary_table <- do.call(rbind, all_tost_results)\n",
    "  rownames(tost_summary_table) <- NULL\n",
    "  tost_summary_table_interpreted <- tost_summary_table %>%\n",
    "    filter(Term != \"(Intercept)\") %>%\n",
    "    arrange(Term) %>%\n",
    "    select(Model, Term, Estimate_log_odds, Original_P_Value, Is_Equivalent_TOST, Notes) %>%\n",
    "    mutate(\n",
    "      Notes = case_when(\n",
    "        Original_P_Value > 0.05 & Is_Equivalent_TOST == TRUE ~ \"true null\",\n",
    "        Original_P_Value > 0.05 & (Is_Equivalent_TOST == FALSE | is.na(Is_Equivalent_TOST)) ~ \"underpowered\",\n",
    "        Original_P_Value <= 0.05 & Is_Equivalent_TOST == TRUE ~ \"true but small\",\n",
    "        Original_P_Value <= 0.05 & (Is_Equivalent_TOST == FALSE | is.na(Is_Equivalent_TOST)) ~ \"meaningful\",\n",
    "        TRUE ~ \"check logic\" # Default case, should not be reached if logic is complete\n",
    "      )\n",
    "    )\n",
    "  print(\"TOST Equivalence Test Summary:\")\n",
    "  tost_summary_table_interpreted\n",
    "} else {\n",
    "  print(\"No TOST results generated. Check warnings.\")\n",
    "}\n",
    "\n",
    "# Interpretation guide for TOST results (when original p-value is > 0.05, i.e., non-significant):\n",
    "# 1. Original_P_Value > 0.05 AND Is_Equivalent_TOST == TRUE:\n",
    "#    Suggests the effect is not statistically different from zero, AND it's statistically within your\n",
    "#    predefined equivalence bounds (i.e., practically negligible or too small to be of interest,\n",
    "#    as defined by your SESOI_d). This supports an interpretation of a \"null\" or \"negligible\" effect.\n",
    "#\n",
    "# 2. Original_P_Value > 0.05 AND Is_Equivalent_TOST == FALSE (or NA):\n",
    "#    The effect is not statistically different from zero, BUT you cannot conclude it's within your\n",
    "#    equivalence bounds. This is an inconclusive result regarding practical equivalence.\n",
    "#    The true effect might be small, or your study might lack the precision (power) to demonstrate\n",
    "#    that it falls within the narrow equivalence bounds. This aligns with the \"lack of power / inconclusive\" scenario.\n",
    "#\n",
    "# 3. Original_P_Value <= 0.05 AND Is_Equivalent_TOST == FALSE:\n",
    "#    The effect is statistically different from zero AND it's not statistically within your equivalence bounds.\n",
    "#    This suggests a \"meaningful\" effect (i.e., different from zero and not negligible).\n",
    "#\n",
    "# 4. Original_P_Value <= 0.05 AND Is_Equivalent_TOST == TRUE:\n",
    "#    The effect is statistically different from zero BUT it's also statistically within your equivalence bounds.\n",
    "#    This is less common but implies a precisely estimated effect that is very small (different from zero, but still negligible)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80403532",
   "metadata": {},
   "source": [
    "# Simulation-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d1ef9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Processing Group: Humans ---\n",
      "\n",
      "  Testing Term: Angleleft (Coefficient: Angleleft)\n",
      "\n",
      "  Testing Term: Angleright (Coefficient: Angleright)\n",
      "\n",
      "  Testing Term: Proximity_scaled (Coefficient: scale(Proximity, scale = FALSE))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Revised simulate_power function\n",
    "simulate_power <- function(df_template, model_template_arg, formula_to_fit, target_term, cohen_d, n_obs) {\n",
    "  # Extract parameters from the template model for the current group\n",
    "  vc_template <- lme4::VarCorr(model_template_arg)\n",
    "  re_variances_template <- sapply(vc_template, function(v) v[1]) # Variances\n",
    "  fixed_intercept_template <- tryCatch(fixef(model_template_arg)[\"(Intercept)\"], error = function(e) 0)\n",
    "\n",
    "  # Determine RE factor names directly from the model's VarCorr object\n",
    "  re_factors_in_formula <- names(re_variances_template)\n",
    "  # Remove any potential NA names if a variance component was NA (though sapply should handle this)\n",
    "  re_factors_in_formula <- re_factors_in_formula[!is.na(re_factors_in_formula)]\n",
    "\n",
    "  # Calculate total latent variance for Cohen's d to log-odds conversion\n",
    "  active_re_variances_sum <- 0\n",
    "  if (length(re_factors_in_formula) > 0) {\n",
    "      # We use re_variances_template directly as it already contains variances for factors in the model\n",
    "      active_re_variances_sum <- sum(re_variances_template[re_factors_in_formula], na.rm = TRUE)\n",
    "  }\n",
    "  total_latent_variance <- active_re_variances_sum + (pi^2 / 3)\n",
    "  log_odds_effect <- cohen_d * sqrt(total_latent_variance)\n",
    "\n",
    "  # Simulate predictors based on the empirical distribution in df_template\n",
    "  sim_data <- data.frame(row_id = 1:n_obs)\n",
    "  sim_data$Angle <- sample(df_template$Angle, n_obs, replace = TRUE)\n",
    "  sim_data$Proximity_raw <- sample(df_template$Proximity, n_obs, replace = TRUE)\n",
    "  sim_data$n_candidates_raw <- sample(df_template$n_candidates, n_obs, replace = TRUE)\n",
    "  sim_data$Actor <- sample(df_template$Actor, n_obs, replace = TRUE)\n",
    "\n",
    "  # Scale predictors as in the original model formula\n",
    "  sim_data$Proximity <- scale(sim_data$Proximity_raw, center = TRUE, scale = FALSE)[,1]\n",
    "  sim_data$n_candidates <- scale(sim_data$n_candidates_raw, center = TRUE, scale = FALSE)[,1]\n",
    "\n",
    "  # Calculate offset\n",
    "  sim_data$offset <- log(1/sim_data$n_candidates_raw / (1 - 1/sim_data$n_candidates_raw))\n",
    "  sim_data$offset[is.infinite(sim_data$offset) | is.na(sim_data$offset)] <- 0 # Handle potential division by zero if n_candidates is 1 or 0\n",
    "\n",
    "  # Simulate Random Effects\n",
    "  total_re_contribution <- numeric(n_obs)\n",
    "  if (length(re_factors_in_formula) > 0) {\n",
    "    for (re_factor_name in re_factors_in_formula) {\n",
    "      # Ensure the variance is positive and the factor exists in df_template\n",
    "      if (re_factor_name %in% names(re_variances_template) && !is.na(re_variances_template[[re_factor_name]]) && re_variances_template[[re_factor_name]] > 0 && re_factor_name %in% names(df_template)) {\n",
    "        original_levels <- unique(df_template[[re_factor_name]])\n",
    "        if(length(original_levels) == 0 || all(is.na(original_levels))) { # Handle cases with no levels or all NA levels\n",
    "            # message(sprintf(\"Warning: No valid levels for RE factor %s in df_template for group. Using a dummy factor.\", re_factor_name))\n",
    "            sim_data[[re_factor_name]] <- factor(rep(1, n_obs)) # Dummy factor\n",
    "            # No RE contribution if no valid levels to sample from or variance is zero\n",
    "            next \n",
    "        }\n",
    "        sim_data[[re_factor_name]] <- factor(sample(original_levels, n_obs, replace = TRUE))\n",
    "        \n",
    "        n_levels_current_re <- nlevels(sim_data[[re_factor_name]])\n",
    "        re_sd <- sqrt(re_variances_template[[re_factor_name]])\n",
    "        population_effects <- rnorm(n_levels_current_re, 0, re_sd)\n",
    "        names(population_effects) <- levels(sim_data[[re_factor_name]])\n",
    "        # Ensure all sampled levels in sim_data[[re_factor_name]] are present in names(population_effects)\n",
    "        # This can be an issue if sampling from original_levels leads to fewer unique levels than n_levels_current_re expects\n",
    "        # A safer way is to map directly from the sampled factor levels\n",
    "        current_sim_levels <- as.character(sim_data[[re_factor_name]])\n",
    "        missing_levels_in_pop_effects <- setdiff(unique(current_sim_levels), names(population_effects))\n",
    "        if(length(missing_levels_in_pop_effects) > 0){\n",
    "            # This case should ideally not happen if population_effects are generated based on levels(sim_data[[re_factor_name]])\n",
    "            # message(sprintf(\"Warning: Mismatch in RE levels for %s. Some simulated levels not in population_effects map.\", re_factor_name))\n",
    "            # For robustness, assign 0 to these missing levels, though it indicates a deeper issue if it occurs.\n",
    "            temp_effects_for_missing <- rep(0, length(missing_levels_in_pop_effects))\n",
    "            names(temp_effects_for_missing) <- missing_levels_in_pop_effects\n",
    "            population_effects <- c(population_effects, temp_effects_for_missing)\n",
    "        }\n",
    "        total_re_contribution <- total_re_contribution + population_effects[current_sim_levels]\n",
    "      } else { \n",
    "        # If RE not in model (VarCorr), variance is zero/NA, or factor not in df_template, create a dummy factor column if it doesn't exist\n",
    "        if (!re_factor_name %in% names(sim_data)) {\n",
    "            sim_data[[re_factor_name]] <- factor(rep(1, n_obs)) # Dummy factor\n",
    "        }\n",
    "        # No RE contribution added\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # Calculate linear predictor (eta)\n",
    "  eta <- fixed_intercept_template + sim_data$offset + total_re_contribution\n",
    "  # Add the target effect (log_odds_effect) for the specific term being tested\n",
    "  # Other fixed effects are assumed to be 0 for this specific power calculation\n",
    "  if (target_term == \"Angleleft\") { eta <- eta + ifelse(sim_data$Angle == \"left\", log_odds_effect, 0) }\n",
    "  else if (target_term == \"Angleright\") { eta <- eta + ifelse(sim_data$Angle == \"right\", log_odds_effect, 0) }\n",
    "  else if (target_term == \"scale(Proximity, scale = FALSE)\") { eta <- eta + sim_data$Proximity * log_odds_effect }\n",
    "  else if (target_term == \"scale(n_candidates, scale = FALSE)\") { eta <- eta + sim_data$n_candidates * log_odds_effect }\n",
    "  else if (target_term == \"ActorY\") { eta <- eta + ifelse(sim_data$Actor == \"Y\", log_odds_effect, 0) }\n",
    "\n",
    "  # Simulate binary outcome\n",
    "  prob <- plogis(eta)\n",
    "  sim_data$Accuracy <- rbinom(n_obs, 1, prob)\n",
    "\n",
    "  # Fit model to simulated data\n",
    "  p_value_target_term <- NA\n",
    "  tryCatch({\n",
    "    # Ensure the offset column in sim_data is named 'offset' as expected by get_formula\n",
    "    model_fit_sim <- lme4::glmer(formula_to_fit, data = sim_data, family = binomial(link = \"logit\"))\n",
    "    model_summary <- broom.mixed::tidy(model_fit_sim, effects = \"fixed\")\n",
    "    term_row <- model_summary[model_summary$term == target_term, ]\n",
    "    if (nrow(term_row) == 1) {\n",
    "      p_value_target_term <- term_row$p.value\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    # message(sprintf(\"Simulation glmer error for %s, term %s, d=%.2f: %s\", deparse(substitute(model_template_arg)), target_term, cohen_d, e$message))\n",
    "    p_value_target_term <- NA\n",
    "  })\n",
    "  return(list(p_value = p_value_target_term, significant = !is.na(p_value_target_term) && p_value_target_term < 0.05))\n",
    "}\n",
    "\n",
    "# Main simulation loop\n",
    "TERMS_TO_TEST <- list(\n",
    "  \"Angleleft\" = \"Angleleft\",\n",
    "  \"Angleright\" = \"Angleright\",\n",
    "  \"Proximity_scaled\" = \"scale(Proximity, scale = FALSE)\"\n",
    "#  \"n_candidates_scaled\" = \"scale(n_candidates, scale = FALSE)\",\n",
    ")\n",
    "\n",
    "effect_sizes_cohen_d_sim <- seq(0.05, 0.4, by = 0.05) # Define range of Cohen's d\n",
    "n_simulations <- 100 # Number of simulations per setting. 1 -> 20min; 20 -> 50min\n",
    "simulation_power_results_list <- list()\n",
    "\n",
    "for (grp_key in GROUP_LIST) {\n",
    "  message(sprintf(\"--- Processing Group: %s ---\", grp_key))\n",
    "  df_grp_template <- df %>% filter(Group == grp_key, list_id != \"-1\", Part != \"p0\")\n",
    "  if (nrow(df_grp_template) == 0) {\n",
    "    message(sprintf(\"  Skipping group %s: No data after filtering.\", grp_key))\n",
    "    next\n",
    "  }\n",
    "  model_template_for_grp <- models[[grp_key]]\n",
    "  if (is.null(model_template_for_grp)) {\n",
    "    message(sprintf(\"  Skipping group %s: Original model not found.\", grp_key))\n",
    "    next\n",
    "  }\n",
    "  formula_for_grp <- get_formula(grp_key)\n",
    "  n_obs_for_sim <- nrow(df_grp_template)\n",
    "\n",
    "  for (term_friendly_name in names(TERMS_TO_TEST)) {\n",
    "    target_coefficient_name <- TERMS_TO_TEST[[term_friendly_name]]\n",
    "    message(sprintf(\"  Testing Term: %s (Coefficient: %s)\", term_friendly_name, target_coefficient_name))\n",
    "\n",
    "    # Check if the target coefficient exists in the original model for this group\n",
    "    original_coeffs <- tryCatch(rownames(summary(model_template_for_grp)$coefficients), error = function(e) character(0))\n",
    "    if (!target_coefficient_name %in% original_coeffs) {\n",
    "        # This can happen if a factor level is not present or reference level logic changes things\n",
    "        # For Angleleft/Angleright, if only one non-reference level exists, the other won't be in summary\n",
    "        # For now, we'll attempt simulation; if term is truly absent, p-value will be NA from simulate_power\n",
    "        message(sprintf(\"    Warning: Target coefficient '%s' not found in original model for group %s. Simulation will proceed but p-value might be NA.\", target_coefficient_name, grp_key))\n",
    "    }\n",
    "\n",
    "    for (es_d in effect_sizes_cohen_d_sim) {\n",
    "    #  message(sprintf(\"    Cohen's d: %.3f\", es_d))\n",
    "      num_cores <- max(1, parallel::detectCores() - 1)\n",
    "      sim_outputs <- parallel::mclapply(1:n_simulations, function(sim_idx) {\n",
    "        simulate_power(\n",
    "          df_template = df_grp_template,\n",
    "          model_template_arg = model_template_for_grp,\n",
    "          formula_to_fit = formula_for_grp,\n",
    "          target_term = target_coefficient_name,\n",
    "          cohen_d = es_d,\n",
    "          n_obs = n_obs_for_sim\n",
    "        )\n",
    "      }, mc.cores = num_cores)\n",
    "      \n",
    "      p_values_from_sims <- sapply(sim_outputs, function(x) if(is.list(x)) x$p_value else NA)\n",
    "      successful_sims <- sum(!is.na(p_values_from_sims))\n",
    "      power_estimate <- if (successful_sims > 0) {\n",
    "        sum(p_values_from_sims < 0.05, na.rm = TRUE) / successful_sims\n",
    "      } else { NA }\n",
    "      \n",
    "      simulation_power_results_list[[length(simulation_power_results_list) + 1]] <- data.frame(\n",
    "        Model = api_to_name[[grp_key]],\n",
    "        Original_Group = grp_key,\n",
    "        Term_Friendly = term_friendly_name,\n",
    "        Term_Coefficient = target_coefficient_name,\n",
    "        Cohens_d = es_d,\n",
    "        Power = power_estimate,\n",
    "        N_sim_successful = successful_sims,\n",
    "        N_sim_total = n_simulations\n",
    "      )\n",
    "    }\n",
    "  }\n",
    "}\n",
    "final_power_simulation <- do.call(rbind, simulation_power_results_list)\n",
    "if (!is.null(final_power_simulation)) rownames(final_power_simulation) <- NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db311a2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Simulation-Based Power Analysis Results:\")\n",
    "head(final_power_simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Minimum detectable effect size for each variable from simulation\n",
    "if (exists(\"final_power_simulation\") && nrow(final_power_simulation) > 0) {\n",
    "  print(\"\\nMinimum detectable effect sizes (80% power, Simulation-Based):\")\n",
    "  mdes_simulation <- final_power_simulation %>%\n",
    "    filter(!is.na(Power) & Power >= 0.80) %>%\n",
    "    group_by(Model, Original_Group, Term_Friendly, Term_Coefficient) %>%\n",
    "    slice_min(order_by = Cohens_d, n = 1, with_ties = FALSE) %>%\n",
    "    ungroup() %>%\n",
    "    select(Model, Original_Group, Term_Friendly, Min_Cohens_d = Cohens_d, Power_at_Min_d = Power)\n",
    "  mdes_simulation\n",
    "} else {\n",
    "  print(\"final_power_simulation table is empty or not found. Run the simulation cell.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48408446",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "simulation_all_tost_results <- list()\n",
    "for (grp_key in names(models)) {\n",
    "  model <- models[[grp_key]]\n",
    "  model_name_descriptive <- api_to_name[[grp_key]]\n",
    "  \n",
    "  # Get model summary for fixed effects\n",
    "  model_summary <- summary(model)$coefficients\n",
    "  model_summary_df <- as.data.frame(model_summary)\n",
    "  model_summary_df$Term <- rownames(model_summary_df)\n",
    "  rownames(model_summary_df) <- NULL\n",
    "  \n",
    "  # Calculate denominator for standardizing coefficients (as you did before)\n",
    "  vc_list <- lapply(lme4::VarCorr(model), function(x) attr(x, \"stddev\")^2)\n",
    "  vc <- sum(unlist(vc_list), na.rm = TRUE) # Added na.rm = TRUE for robustness\n",
    "  effect_size_denom_t <- sqrt(vc + (pi^2/3))\n",
    "  \n",
    "  # Get SESOI (Min_Cohens_d) for this group from the analytical power analysis\n",
    "  mde_row <- mdes_simulation %>%\n",
    "    filter(Original_Group == grp_key)\n",
    "  \n",
    "  sesoi_d <- NA\n",
    "  notes_for_group <- \"\"\n",
    "  \n",
    "  if (nrow(mde_row) == 0 || is.na(mde_row$Min_Cohens_d[1])) {\n",
    "    message(sprintf(\"Warning: MDE/SESOI (Min_Cohens_d) not found for group %s (Model: %s). TOST p-values will be NA.\", grp_key, model_name_descriptive))\n",
    "    notes_for_group <- \"MDE/SESOI not available\"\n",
    "  } else {\n",
    "    sesoi_d <- mde_row$Min_Cohens_d[1]\n",
    "  }\n",
    "  \n",
    "  group_tost_results_list <- list()\n",
    "  \n",
    "  for (i in 1:nrow(model_summary_df)) {\n",
    "    term_name <- model_summary_df$Term[i]\n",
    "    estimate_log_odds <- model_summary_df$Estimate[i]\n",
    "    se_log_odds <- model_summary_df$`Std. Error`[i]\n",
    "    original_p_value <- model_summary_df$`Pr(>|z|)`[i]\n",
    "\n",
    "    # Standardize estimate and SE\n",
    "    estimate_std <- estimate_log_odds / effect_size_denom_t\n",
    "    se_std <- se_log_odds / effect_size_denom_t\n",
    "    \n",
    "    p_upper_tost <- NA\n",
    "    p_lower_tost <- NA\n",
    "    p_value_tost <- NA\n",
    "    is_equivalent <- NA\n",
    "    term_notes <- notes_for_group\n",
    "    \n",
    "    if (term_name == \"(Intercept)\") {\n",
    "      term_notes <- paste(notes_for_group, \"TOST not typically applied to intercept\", sep=\"; \")\n",
    "    } else if (is.na(sesoi_d)) {\n",
    "      # Already handled by notes_for_group, is_equivalent remains NA\n",
    "    } else if (is.na(estimate_std) || is.na(se_std) || se_std <= 0) {\n",
    "        term_notes <- paste(notes_for_group, \"Invalid estimate or SE for TOST\", sep=\"; \")\n",
    "    } else {\n",
    "      # Equivalence bounds (symmetric around 0 on the standardized scale)\n",
    "      # We are testing if the effect is within [-sesoi_d, +sesoi_d]\n",
    "      equiv_bound_upper <- sesoi_d\n",
    "      equiv_bound_lower <- -sesoi_d\n",
    "      \n",
    "      # Test 1: Is the effect significantly less than the upper equivalence bound?\n",
    "      # H0: estimate_std >= equiv_bound_upper  vs. H1: estimate_std < equiv_bound_upper\n",
    "      z_upper <- (estimate_std - equiv_bound_upper) / se_std\n",
    "      p_upper_tost <- pnorm(z_upper, lower.tail = TRUE)\n",
    "      \n",
    "      # Test 2: Is the effect significantly greater than the lower equivalence bound?\n",
    "      # H0: estimate_std <= equiv_bound_lower vs. H1: estimate_std > equiv_bound_lower\n",
    "      z_lower <- (estimate_std - equiv_bound_lower) / se_std\n",
    "      p_lower_tost <- pnorm(z_lower, lower.tail = FALSE)\n",
    "      \n",
    "      # For equivalence, both one-sided tests must be significant\n",
    "      p_value_tost <- max(p_upper_tost, p_lower_tost)\n",
    "      is_equivalent <- p_value_tost < alpha_tost\n",
    "    }\n",
    "    \n",
    "    group_tost_results_list[[term_name]] <- data.frame(\n",
    "      Model = model_name_descriptive,\n",
    "      Original_Group = grp_key,\n",
    "      Term = term_name,\n",
    "      Estimate_log_odds = estimate_log_odds,\n",
    "      Std_Error_log_odds = se_log_odds,\n",
    "      Original_P_Value = original_p_value,\n",
    "      Estimate_std = estimate_std, # Standardized effect size (Cohen's d like)\n",
    "      Std_Error_std = se_std,\n",
    "      SESOI_d = sesoi_d,\n",
    "      P_Upper_TOST = p_upper_tost,\n",
    "      P_Lower_TOST = p_lower_tost,\n",
    "      P_Value_TOST = p_value_tost,\n",
    "      Is_Equivalent_TOST = is_equivalent,\n",
    "      Notes = term_notes\n",
    "    )\n",
    "  }\n",
    "  if (length(group_tost_results_list) > 0) {\n",
    "    simulation_all_tost_results[[grp_key]] <- do.call(rbind, group_tost_results_list)\n",
    "  }\n",
    "}\n",
    "\n",
    "if (length(simulation_all_tost_results) > 0) {\n",
    "  simulation_tost_summary_table <- do.call(rbind, simulation_all_tost_results)\n",
    "  rownames(simulation_tost_summary_table) <- NULL\n",
    "  simulation_tost_summary_table_interpreted <- simulation_tost_summary_table %>%\n",
    "    filter(Term != \"(Intercept)\") %>%\n",
    "    arrange(Term) %>%\n",
    "    select(Model, Term, Estimate_log_odds, Original_P_Value, Is_Equivalent_TOST, Notes) %>%\n",
    "    mutate(\n",
    "      Notes = case_when(\n",
    "        Original_P_Value > 0.05 & Is_Equivalent_TOST == TRUE ~ \"true null\",\n",
    "        Original_P_Value > 0.05 & (Is_Equivalent_TOST == FALSE | is.na(Is_Equivalent_TOST)) ~ \"underpowered\",\n",
    "        Original_P_Value <= 0.05 & Is_Equivalent_TOST == TRUE ~ \"true but small\",\n",
    "        Original_P_Value <= 0.05 & (Is_Equivalent_TOST == FALSE | is.na(Is_Equivalent_TOST)) ~ \"meaningful\",\n",
    "        TRUE ~ \"check logic\" # Default case, should not be reached if logic is complete\n",
    "      )\n",
    "    )\n",
    "  print(\"TOST Equivalence Test Summary:\")\n",
    "  simulation_tost_summary_table_interpreted\n",
    "} else {\n",
    "  print(\"No TOST results generated. Check warnings.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea389f0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
